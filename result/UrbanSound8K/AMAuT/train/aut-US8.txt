FCETransform(
  (embedding): FCEmbedding(
    (restnet): FCEResNet(
      (root): Sequential(
        (0): StdConv1d(64, 64, kernel_size=(14,), stride=(2,), padding=(6,), bias=False)
        (1): BatchNorm1d(64, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (maxPool): MaxPool1d(kernel_size=6, stride=2, padding=2, dilation=1, ceil_mode=False)
      (layers): ModuleList(
        (0): FCEResNetBlock(
          (conv1): StdConv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)
          (norm1): BatchNorm1d(64, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): StdConv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
          (norm2): BatchNorm1d(64, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): StdConv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
          (norm3): BatchNorm1d(256, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): StdConv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
          (ds_gn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1-6): 6 x FCEResNetBlock(
          (conv1): StdConv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
          (norm1): BatchNorm1d(64, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): StdConv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
          (norm2): BatchNorm1d(64, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): StdConv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
          (norm3): BatchNorm1d(256, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): FCEResNetBlock(
          (conv1): StdConv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
          (norm1): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): StdConv1d(128, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
          (norm2): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): StdConv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)
          (norm3): BatchNorm1d(512, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): StdConv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
          (ds_gn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (8-15): 8 x FCEResNetBlock(
          (conv1): StdConv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)
          (norm1): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): StdConv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
          (norm2): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): StdConv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)
          (norm3): BatchNorm1d(512, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (patch_embedding): Conv1d(512, 768, kernel_size=(1,), stride=(1,))
  )
  (tf_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (layers): ModuleList(
    (0-11): 12 x AttentionBlock(
      (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attention): MultiHeadAttention(
        (q): Linear(in_features=768, out_features=768, bias=True)
        (k): Linear(in_features=768, out_features=768, bias=True)
        (v): Linear(in_features=768, out_features=768, bias=True)
        (o): Linear(in_features=768, out_features=768, bias=True)
      )
      (ffn): MultilayerPerceptron(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (act_fn): GELU(approximate='none')
        (drop_out): Dropout(p=0.0, inplace=False)
      )
      (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    )
  )
  (drop_out): Dropout(p=0.15, inplace=False)
)